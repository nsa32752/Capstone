**주요 변경사항만 포함되어있는 회의록**

개발 일정
7.15-7.24: Data Civilizer 논문 읽기 및 프레젠테이션
7.24-8.07: 설계 및 라이브러리 타당성 검사
8.07-     : 구현

#1
1. 클리니스 한 결과, DB에 반영할 것인가? 아니면 데이터프레임에서만 삭제할 것인가?
	-> 일단 데이터 프레임에서만 삭제
2. 유사성 계산후 프로파일링에 넘겨줄때 일단은 다 넘겨줌, 임계값 설정 필요
	-> 추후에 다시 논의
3. 아랑고 디비 키에 한글 입력 불가 : 노드 접근 용도이기 때문에 칼럼이 들어가야 함
	-> 대부분의 디비 칼럼에는 영어를 사용한다. 그렇기 때문에 테스트 파일의 칼럼 이름을 영어로 바꿀것
칼럼 유사성 -> type 비교로 수정: 칼럼 이름이 같을 경우만 검사했는데, type이 같을 경우 비교하는 것으로 수정할 것
gitlab에 코드 upload

PyArango 사용할 경우,
1. collection(table) 생성시 각, 컬렉션 변수에 맞는 클래스 생성 해야함
	그러나, 컬렉션 명을 변수로 넘겨주기 때문에 사실상 불가능
	클래스를 생성하지 않는 경우 그래프 생성 불가능
	그래프, 릴레이션 생성 역시 각 이름으로 된 클래스가 있어야 함
	=> 1. github에 이슈 올려보기  -  https://github.com/ArangoDB-Community/pyArango/issues/191
	     2. 자바로 변경해서 해볼 것

#2
1. 설계 단계까지는 그래프의 노드가 의미하는 것이 테이블이었음(ver2), 구현과정에서 칼럼끼리 표시하는 것으로 바뀜
	-> 어느것 채택?
2. 그래프 그리는것은 자바로 사용하면 될듯
	자바 연결할 때 py4j 라이브러리 사용 -> bsd license
3. 아랑고디비에 컬렉션, 릴레이션, document추가 시 key값 중복이나, table exsists already 에러와 같은 것들 예외처리 
4. iqr 정확한가? 추후 논의
5. 논의 사항
	IND 화살표 방향 수정(PK-FK 관계)
	1) py4j 라이브러리 사용 -> eclipse에서 자바를 한번 실행시켜야하는 과정이 필요해서 이 과정을 사용하지 않는 방법 찾는 중
		: 자바에서 http 서버를 열어서 처리하는 방법
	2) 그래프의 노드가 의미하는 것이 원래는 테이블 이었으나 현재는 칼럼, 어느 것으로 해야하나? 현재 칼럼 쓰는 방법으로 사용
	3) update에서 DB에서 업데이트 된 사항을 쿼리로그를 사용하여 알아내는 방법? 사용, 시스템프로그래밍 시간에 미니 쉘을 만들면서 history를 구현한 경험에서 착안하여
									키보드 화살표를 통해 이전에 실행한 쿼리를 가져올 수 있기 때문에, 이를 조회하는 기능이 있을것이라 생각했고
									쿼리 로그 기록을 알아내는 쿼리문을 발견.
	4) 사용자가 원하는 데이터에 대한 쿼리를 던진 후 그 결과에 대해서는 어떠한 방식으로 보여주어야 하나?
		그래프 비즈 사용 -> IND와 칼럼유사성은 구분하는 방식으로

외부 데이터를 가져오기 전 선행해서 판별하는 작업 필요: 샘플 데이터 가져다가 비교(스키마 유사성만 확인) -> 추후에 

쿼리 로그 수정하기, 
자바 apache http 설정 -> 자바를 runof로 사용: exec 
	-> 그냥 서버를 계속 띄워놓는게 나을듯, 매번 그래프를 그릴때마다 콜할 수는 없지 않나
라이브러리 : bsd apache mit 정도면 사용 가능
폴리스토어에서 데이터프레임 넘길때 -> 페이징작업해줄것(50개 또는 100개 잘라서 가져오기 1억건이면 100건씩 잘라서 여러번 가져오기
						, 전체 카운트 가져와서 몇개 가져올지 정하기) -> 프로파일링
그러면 1억건에 대해서 프로파일링을 하면? 터질 가능성이 아주 높음, 메모리 문제 -> 증분 프로파일링 
	=> 해보고 프로파일링 2개 비교해서 정확도 판단 다음에 회의

#3
1. 쿼리 로그 수정 
- 쿼리 로그에서 테이블 명 추출해서 집합 처리
- 이전 방식은 로그마다 프로파일링 진행했는데, 데이터가 10건 업데이트 되었다 했을때, 시스템에서 10번의 업데이트 진행
	-> 한번만 진행하도록 쿼리 로그에서 테이블 명만 중복없이 추리는 작업 추가
2. 그래프 비즈 연동 -> to no.12
- 유사성은 직선, IND는 화살표 
3. 쿼리문 던졌을 때 그래프 띄어주기
4. 증분 프로파일링
table row 개수, missing value
column 별
- value_counts, distinct_count, type, max, min, range
- mean --> 평균적으로 0.02~0.03차이
## - ** median_length, chi_squared, variance, correlations
5. 폴리스토어 페이징 작업
6. IND에서 PK-FK 관계 화살표 방향 정확하게 표시하기 
- from a to b: (a&b)/a == 1인 경우 IND, a가 FK b가 PK
- 논문에서 R[X]가 FK table이고 S[Y]가 PK table일 때 둘 사이에 IND가 성립할 때 이를 from R[X] -> to S[Y]라 나타냄
7. iqr 정확?
8. 클리니스
- 디비에 널값 -> 데이터 프레임으로 변환시 텍스트로 읽힘 -> 클리니스에서 결측값으로 재변경
9. 주기적으로 디비 로그 긁어오면서 사용자의 쿼리문 입력 항시 대기 -> multiprocessing으로 하고 싶은데 방법 찾는중
10. ArangoDB 그래프를 가져다 쓰지 않는다면, 자바를 연결하는 의미가 있나? 쿼리 던져서 가져오는데...
11. 페이징 작업시 한번에 몇개를 가져와야하나
12. 칼럼 유사성과 IND 계산 함수 분리
	기존 방식에서는 한번에 계산. 그러나, 예를 들어 업데이트 과정에서 from과 to에 test1이 포함된 모든 릴레이션을 지우는데 이 과정에서 칼럼 유사성은 다시 업데이트 되지만
	test1이 PK인 경우를 계산하는 IND과정은 수행하지 않게 됨. 이를 해결하기 위해 test1을 from, to 각각 놓아 계산할 경우 칼럼 유사성에 대해 중복이 생김
	그래서, 함수를 분리하는 작업을 시행. 칼럼 유사성에서는 PK-FK 관계를 따지지 않음.(inter(col1, col2)/col1+col2-inter(col1, col2))
	=> 자바 연결 안하는 것으로 결정

#4
메타 정보에 키워드를 집어넣으면 전부 집어넣는가? 전부 집어넣고 DISTINCT VALUE도 집어 넣는가?
유사도 계산 -> 자카드로 변경(시간 단축 가능)
TRY EXCEPT 처리 필요 --> 수많은 예외사항이 존재, 다른 데이터를 돌렸을 때 바로 에러가 발생함

#5
1. 데이터가 길 때 디비에 잘려 들어감 -> 그러지 않는 경우 에러 발생
	A. ALTER TABLE modify -> varchar를 text로 변경, 변경할 경우 6만개가 넘어감
		--> 인덱싱을 사용하지 않기 때문에 varchar대신 text를 사용해도 상관없음
2. 유사도 계산 자카드로 수정
3. 범주형 데이터 판별 추가
4. 키워드 분석을 어디에 활용할 것인가?
5. 키워드를 가지고 유사도를 확인할 경우  distinct value를 넣는 이유가 없다
	A. LDA, TF-IDF등
	B. 어떤 텍스트에 대해 특정 토픽을 판별 -> 이것이 메타 정보 일것
	C. 근데 이 토픽을 키워드로 뽑는게 맞는가? 일단은 키워드로 진행
	D. 최근의 트렌드는 자연어스러운 토픽 - 지금은 명사 위주
	E. 키워드 자카드 계산 시 스코어링
	F. 스트링에 대해서 한 로우에 대해 단건으로 키워드를 추출할 수 있도록 수정 필요 -> 단건 비교 불가능할 경우 이슈 바로 공유 할 것 


#6
1. LDA 적용할 것
2. 각 로우에 대해 키워드를 뽑아내고 문서내에서도 유사도 분석을 할 수 있었으면 좋겠다

#7
db_connect
1) column명 특수 기호 _로 바꾸기 
2) column type TEXT로 수정 - varchar와 구분하려 했지만 그러기 위해서는 
각 칼럼의 최대길이를 찾아야함 => sql로 찾아서 해당 col만 바꾼다면? 시간 측면 고려해볼것
profiling+db_connect
1) 파일 경로 안가져오는 방법으로 수정
col_sim
1) 수치형 칼럼 유사도 계산 -> 원래 방식으로 재수정
2) 텍스트 칼럼 유사도 계산 -> 자카드
3) text 키워드 알고리즘 LDA 적용

#8
1. 칼럼명에 예약어가 들어가있는 경우 이를 어떻게 처리해야 할 것인가
2. 칼럼명에 공백 또는 특수문자가 들어가 있는 경우 _로 대체
3. konlpy 적용? 다시 보고
4. column type TEXT로 수정 - varchar와 구분하려 했지만 그러기 위해서는 
각 칼럼의 최대길이를 찾아야함 => sql로 찾아서 해당 col만 바꾼다면? 시간 대신 메모리 향상 가능 -> 적용
5. 수치형/범주형은 원래 식대로 계산하고 텍스트는 자카드로 계산하는 방식으로 변경
6. iqr SQL문 사용해서 구함 -> 보류(수치형 IQR 일단 제거 -> 필드명을 가지고 유사성을 판단해서 비슷하면 IQR 체크해서 거르기)
7. 증분 작업을 수행하면서 수치형 데이터를 끊었을 때 이 데이터가 프로파일링에서 범주형으로 판별되는 경우 발생, 
=> distinct_value만 가져오고 이를 기반으로 min, max mean 등의 값은 나중에 계산











